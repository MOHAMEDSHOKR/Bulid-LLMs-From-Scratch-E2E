# Dropout 

Dropout in deep learning is a technique where randomly selected hidden layer units
are ignored during training, effectively “dropping” them out. This method helps prevent
overfitting by ensuring that a model does not become overly reliant on any specific
set of hidden layer units. It’s important to emphasize that dropout is only used
during training and is disabled afterward.


![1_iWQzxhVlvadk6VAJjsgXgg](https://github.com/user-attachments/assets/05800aff-c982-40d4-b599-fcd164335361)
During training, random neurons are "dropped." At inference, all neurons are active.


In the transformer architecture, including models like GPT, dropout in the attention
mechanism is typically applied at two specific times: 

* after calculating the attention weights
* or after applying the attention weights to the value vectors.

Here we will apply the dropout mask after computing the attention weights, as illustrated in figure
3.22, because it’s the more common variant in practice.

In the following code example, we use a dropout rate of 50%, which means masking
out half of the attention weights. (When we train the GPT model in later chapters,
we will use a lower dropout rate, such as 0.1 or 0.2.) We apply PyTorch’s dropout
implementation first to a 6 × 6 tensor consisting of 1s for simplicity:
    
    torch.manual_seed(123)
    dropout = torch.nn.Dropout(0.5) -------------> We choose a dropout rate of 50%.
    example = torch.ones(6, 6) --------------> Here, we create a matrix of 1s.
    print(dropout(example))

![image](https://github.com/user-attachments/assets/3d5e0dfe-0237-48b3-ab0d-8702f4dc6a10)
Figure 3.22 Using the causal attention mask (upper left), we apply an additional
dropout mask (upper right) to zero out additional attention weights to reduce overfitting
during training.


--------------------------------------------------------------------------------------

As we can see, approximately half of the values are zeroed out:

    tensor([[2., 2., 0., 2., 2., 0.],
    [0., 0., 0., 2., 0., 2.],
    [2., 2., 2., 2., 0., 2.],
    [0., 2., 2., 0., 0., 2.],
    [0., 2., 0., 2., 0., 2.],
    [0., 2., 2., 2., 2., 0.]])

    
When applying dropout to an attention weight matrix with a rate of 50%, half of the
elements in the matrix are randomly set to zero. To compensate for the reduction in
active elements, the values of the remaining elements in the matrix are scaled up by a
factor of 1/0.5 = 2. This scaling is crucial to maintain the overall balance of the atten-tion weights, 

ensuring that the average influence of the attention mechanism remains
consistent during both the training and inference phases.
Now let’s apply dropout to the attention weight matrix itself:

    torch.manual_seed(123)
    print(dropout(attn_weights))

The resulting attention weight matrix now has additional elements zeroed out 
and the remaining 1s rescaled:

    tensor([[2.0000, 0.0000, 0 .0000, 0.0000, 0.0000, 0.0000],
    [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
    [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],
    [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],
    [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],
    [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],
    grad_fn=<MulBackward0>

## Note :
the resulting dropout outputs may look different depending on your operating
system; you can read more about this inconsistency here on the PyTorch issue
tracker at https://github.com/pytorch/pytorch/issues/121595.
Having gained an understanding of causal attention and dropout masking, we can
now develop a concise Python class. This class is designed to facilitate the efficient
application of these two techniques.
